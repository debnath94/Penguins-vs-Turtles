{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16e6de9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fec54d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files\n",
    "train_df = pd.read_csv(r\"E:\\LiveProject\\Deep_Learning\\Penguins vs Turtles\\train_anno.csv\")\n",
    "valid_df = pd.read_csv(r\"E:\\LiveProject\\Deep_Learning\\Penguins vs Turtles\\valid_anno.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd54e004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image dimensions\n",
    "image_height = 75\n",
    "image_width = 75\n",
    "num_classes = 2  # Number of classes in your problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f70bc31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image data generator with preprocessing\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f3af9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generate the training dataset from the train_df CSV file\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='filepaths',\n",
    "    y_col='labels',\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "080d0640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generate the validation dataset from the valid_df CSV file\n",
    "valid_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=valid_df,\n",
    "    x_col='filepaths',\n",
    "    y_col='labels',\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8be0c79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the deep learning model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(image_height, image_width, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d160b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping callback\n",
    "#early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cba0b575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47ee3223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "13/13 [==============================] - 6s 316ms/step - loss: 0.6894 - accuracy: 0.5600 - val_loss: 0.6758 - val_accuracy: 0.6429\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 3s 217ms/step - loss: 0.6368 - accuracy: 0.6500 - val_loss: 0.5986 - val_accuracy: 0.5714\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 3s 206ms/step - loss: 0.4829 - accuracy: 0.7850 - val_loss: 0.6657 - val_accuracy: 0.6429\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 3s 206ms/step - loss: 0.4557 - accuracy: 0.8125 - val_loss: 0.7407 - val_accuracy: 0.7143\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 3s 203ms/step - loss: 0.4480 - accuracy: 0.8100 - val_loss: 0.5694 - val_accuracy: 0.7857\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 3s 209ms/step - loss: 0.3647 - accuracy: 0.8525 - val_loss: 0.5595 - val_accuracy: 0.8571\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 3s 214ms/step - loss: 0.3006 - accuracy: 0.8850 - val_loss: 0.5135 - val_accuracy: 0.8571\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 3s 209ms/step - loss: 0.2999 - accuracy: 0.8725 - val_loss: 0.5811 - val_accuracy: 0.7143\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 3s 199ms/step - loss: 0.3140 - accuracy: 0.8650 - val_loss: 0.4068 - val_accuracy: 0.8571\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 3s 207ms/step - loss: 0.2154 - accuracy: 0.9150 - val_loss: 0.5722 - val_accuracy: 0.8571\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 3s 208ms/step - loss: 0.1814 - accuracy: 0.9275 - val_loss: 0.4627 - val_accuracy: 0.8571\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 3s 205ms/step - loss: 0.1539 - accuracy: 0.9400 - val_loss: 0.5560 - val_accuracy: 0.7857\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 3s 206ms/step - loss: 0.1507 - accuracy: 0.9350 - val_loss: 0.5231 - val_accuracy: 0.8571\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 3s 199ms/step - loss: 0.0855 - accuracy: 0.9750 - val_loss: 0.5742 - val_accuracy: 0.8571\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 3s 206ms/step - loss: 0.0747 - accuracy: 0.9700 - val_loss: 1.0024 - val_accuracy: 0.7143\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 3s 196ms/step - loss: 0.0917 - accuracy: 0.9675 - val_loss: 0.5117 - val_accuracy: 0.8571\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 3s 197ms/step - loss: 0.0721 - accuracy: 0.9750 - val_loss: 0.7395 - val_accuracy: 0.7857\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 3s 208ms/step - loss: 0.0790 - accuracy: 0.9725 - val_loss: 0.8319 - val_accuracy: 0.7857\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 3s 200ms/step - loss: 0.0736 - accuracy: 0.9675 - val_loss: 0.6520 - val_accuracy: 0.8571\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 3s 201ms/step - loss: 0.0564 - accuracy: 0.9800 - val_loss: 0.8018 - val_accuracy: 0.8571\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "# Train the model with early stopping\n",
    "history = model.fit(train_generator, validation_data=valid_generator, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d1f7957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8018 - accuracy: 0.8571\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation dataset\n",
    "valid_loss, valid_accuracy = model.evaluate(valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f60d34d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.8017741441726685\n",
      "Validation Accuracy: 0.8571428656578064\n"
     ]
    }
   ],
   "source": [
    "print('Validation Loss:', valid_loss)\n",
    "print('Validation Accuracy:', valid_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f63d220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: P.h2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: P.h2\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('P.h2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50778c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
